\documentclass[12pt]{article}          
%\usepackage[parfill]{parskip}  
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
%\usepackage{bm}
%\usepackage{epstopdf}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{nicefrac}
%\usepackage{braket}
\usepackage{physics}
\usepackage[americanvoltages]{circuitikz}
\usepackage{siunitx}
\usepackage[yyyymmdd]{datetime}
\renewcommand{\dateseparator}{--}

\usepackage[margin=.5in, headsep=0.25in, includefoot, heightrounded]{geometry}

\usepackage{siunitx}
\DeclareSIUnit\micron{\micro\metre}
\DeclareSIUnit\cm{\centi\metre}
\DeclareSIUnit\nm{\nano\metre}
\DeclareSIUnit\mrad{\milli\rad}

\newcommand{\re}{\mathrm{Re} \;}
\newcommand{\im}{\mathrm{Im} \;}

\newcommand{\R}{\mathbf{r}}

\newcommand{\Hz}{H^{(z)}}
\newcommand{\Hp}{H^{(\rho)}}

\newcommand{\Tn}[2]{T_{#1}\left(#2\right)}
\newcommand{\Un}[2]{U_{#1}\left(#2\right)}

%\lstset{basicstyle=\ttfamily,breaklines=true,breakatwhitespace=true,frame=l,columns=flexible}

\numberwithin{equation}{section}

\begin{document}

%%%%%%

\title{Ultrashort Pulse Ionization Notes}
\author{Josh Karpel}
\date{\today}

\maketitle

%%%%%%

\tableofcontents

%%%%%%

\newpage
\section{Ultrashort Pulses}

%%%

\subsection{Pulse Construction}
A simple model of a pulse is a superposition of electric fields at different frequencies. We will consider the kind of pulse that might come out of a pulsed laser, which will have a base frequency $\omega_0$ and a series of $N-1$ evenly-spaced higher frequencies with equal amplitude and zero phase difference, so that there are $N$ total modes:
\begin{align}
\omega_n &= \omega_0 + \delta \, n, \qquad n = 0, 1, 2, \cdots, N-1 \\
\tilde{E}_n &= E_0.
\end{align}
The electromagnetic field of this pulse can be represented as a complex amplitude and phase. The real part is the electric field. The squared amplitude of the electric field is the power. To summarize:
\begin{align}
E(t) &= \sum_{n=0}^{N-1} E_n \, e^{-i \omega_n t} \\
E(t) &=  \re E(t) \\
P(t) &= |E(t)|^2.
\end{align}
We can generate a more compact expression for $E(t)$ by expanding it:
\begin{align}
E(t) &= \sum_{n=0}^{N-1} E_n \, e^{-i \omega_n t} \nonumber \\
&= \sum_{n=0}^{N-1} E_0 \, e^{-i \omega_0 t} e^{-i \delta n t} \\
&= E_0 \, e^{-i \omega_0 t} \sum_{n=0}^{N-1} e^{-i \delta n t} \\
E(t) &= E_0 \, e^{-i \omega_0 t} \, \frac{1-e^{-i \delta N t}}{1-e^{-i \delta t}}.
\end{align}
To better categorize the pulses we typically think about $\omega_0$ as a multiple of $\delta$, which we call the pulse frequency ratio ($R = \omega_0/\delta$). Then the electric field is
\begin{align*}
E(t) &= \re E_0 \, e^{-i R \delta t} \, \frac{1-e^{-i \delta N t}}{1-e^{-i \delta t}}.
\end{align*}
The electric field is uniquely specified by the pulse frequency ratio $R$, the mode frequency spacing $\delta$, and the number of modes $N$. The amplitude envelope is given by
\begin{align*}
|E(t)|^2 &= |E_0 \, e^{-i \omega_0 t} \, \frac{1-e^{-i \delta N t}}{1-e^{-i \delta t}}|^2 \\
&= |E_0|^2 \, e^{-i \omega_0 t} e^{i \omega_0 t} \, \frac{1-e^{-i \delta N t}}{1-e^{-i \delta t}} \frac{1-e^{i \delta N t}}{1-e^{i \delta t}} \\
&= |E_0|^2 \, \frac{1-e^{-i \delta N t} - e^{i \delta N t} + 1}{1-e^{-i \delta t} - e^{i \delta t} + 1} \\
&= |E_0|^2 \, \frac{2 + 2 \cos{\delta N t}}{2 + 2 \cos{\delta t}} \\
|E(t)|^2 &= |E_0|^2 \, \frac{\sin^2{\frac{\delta N t}{2}}}{\sin^2{\frac{\delta t}{2}}}.
\end{align*}
The envelope is uniquely specified by the mode frequency spacing and the number of modes.

\subsection{Envelope Shape and Pulse Duration}
Typically, when deciding on a pulse to use, we first choose a number of modes, and then choose a ``pulse width'' which characterizes over how long the central region of the pulse (the amount of time when all the phases are very close so that we get a large amplitude) occurs. We must determine the frequency spacing based on this desired pulse width. To make the correspondence clean, we note that the amplitude envelope has zeros at
\begin{align*}
t_n = \frac{2\pi}{n \delta}, \qquad n = 0, 1, \cdots, N-1
\end{align*}
The pulse width $\tau$ is then defined as the first zero in the amplitude, so that
\begin{align*}
\tau \equiv \frac{2\pi}{N\delta} \\
\delta = \frac{2\pi}{N\tau}.
\end{align*}
The actual FWHM of the electric field is typically around a third of $\tau$. The duration of a full pulse cycle is $N\tau = 2\pi/\delta$ (half of the envelope zeros are on each side of the pulse). For a predetermined number of modes, specifying the pulse width and the pulse frequency ratio is enough to completely determine the electric field at any time. In practice, we often add a smoothing window that forces the electric field to zero at the end points, such as
\begin{align*}
E(t) \rightarrow E(t) \left[\left(1 + e^{\frac{t+t_\mathrm{window}}{\tau}}\right)^{-1} - \left(1 + e^{-\frac{t-t_\mathrm{window}}{\tau}}\right)^{-1}\right],
\end{align*}
where $t_\mathrm{window} \equiv N \tau/2$.

\subsection{Pulse Fluence}
The total pulse energy density over a single period can be determined analytically:
\begin{align*}
I &= \int_{-\pi/\delta}^{\pi/\delta} c \, \epsilon_0 |E(t)|^2 \dd{t} \\
&= \int_{-\pi/\delta}^{\pi/\delta} c \, \epsilon_0 |E_0|^2 \, \frac{\sin^2{\frac{\delta N t}{2}}}{\sin^2{\frac{\delta t}{2}}} \dd{t} \\
&= c \, \epsilon_0 |E_0|^2 \int_{-\pi/\delta}^{\pi/\delta} \frac{\sin^2{\frac{\delta N t}{2}}}{\sin^2{\frac{\delta t}{2}}} \dd{t} \\
&= c \, \epsilon_0 |E_0|^2 \, \frac{\delta}{2} \, \int_{-\pi/2}^{\pi/2} \left(\frac{\sin Nx}{\sin x}\right)^2 \dd{x} \\
I &= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \int_{-\pi/2}^{\pi/2} \left(\frac{\sin Nx}{\sin x}\right)^2 \dd{x}.
\end{align*}
At this point we will use Chebyshev polynomials to evaluate the integral. The Chebyshev polynomials of the first ($T_n$) and second ($U_n$) kind respectively satisfy
\begin{align*}
\Tn{n}{\cos x} &= \cos(n \, x) \\
\Un{n}{\cos x} &= \frac{\sin((n+1) \, x)}{\sin x}.
\end{align*}
Note then that
\begin{align*}
\left(\frac{\sin Nx}{\sin x}\right)^2 = \left[\Un{N-1}{\cos x}\right]^2.
\end{align*}
The Chebyshev polynomials of the second kind obey a product-to-sum identity:
\begin{align*}
\Un{n}{x} \Un{m}{x} = \sum_{k=0}^{n} \Un{m-n+2k}{x},
\end{align*}
which in our case ($n=m$) reduces to
\begin{align*}
\left[\Un{n}{x}\right]^2 = \sum_{k=0}^{N} \Un{2k}{x}.
\end{align*}
The terms we're summing over can themselves be represented as a sum over Chebyshev polynomials of the first kind:
\begin{align*}
\Un{2k}{x} = 2 \sum_{j \, \mathrm{even}}^{2k} \Tn{j}{x} - 1.
\end{align*}
Go back and plug this into the sum so that it becomes a double sum:
\begin{align*}
\left[\Un{n}{x}\right]^2 &= \sum_{k=0}^{n} \left(2 \sum_{j \, \mathrm{even}}^{2k} \Tn{j}{x} - 1\right) \\
&= 2 \sum_{k=0}^{n} \sum_{j \, \mathrm{even}}^{2k} \Tn{j}{x} - n
\end{align*}
Now we apply all of this to the original integral:
\begin{align*}
I &= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \int_{-\pi/2}^{\pi/2} \left(\frac{\sin Nx}{\sin x}\right)^2 \dd{x} \\
&= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \int_{-\pi/2}^{\pi/2} \left[\Un{N-1}{\cos x}\right]^2 \dd{x} \\
&= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \int_{-\pi/2}^{\pi/2} \left[2 \sum_{k=0}^{N-1} \sum_{j \, \mathrm{even}}^{2k} \Tn{j}{\cos x} - \left(N-1\right) \right] \dd{x} \\
&= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \left[\int_{-\pi/2}^{\pi/2} 2 \sum_{k=0}^{N-1} \sum_{j \, \mathrm{even}}^{2k} \Tn{j}{\cos x} \dd{x} - \pi\left(N-1\right) \right] \\
I &= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \left[2 \sum_{k=0}^{N-1} \sum_{j \, \mathrm{even}}^{2k} \int_{-\pi/2}^{\pi/2} \Tn{j}{\cos x} \dd{x} - \pi\left(N-1\right) \right].
\end{align*}
The remaining integral is actually easy to evaluate. Note that the $T_j$ involved in the sum over integrals are either $j=0$ or even. When $j=0$,
\begin{align*}
\int_{-\pi/2}^{\pi/2} T_0(\cos x) \dd{x} = \int_{-\pi/2}^{\pi/2} 1 \dd{x} = \pi. 
\end{align*}
There are exactly $N$ such terms. All of the other terms have $j$ even, and
\begin{align*}
\int_{-\pi/2}^{\pi/2} \Tn{j}{\cos x} \dd{x} = \int_{-\pi/2}^{\pi/2} \cos(jx) \dd{x} = \frac{1}{j} \eval{\sin(jx)}_{-\pi/2}^{\pi/2} = 0.
\end{align*}
Using that result, we have
\begin{align*}
I &= \frac{2}{\delta} \, c \, \epsilon_0 |E_0|^2 \left[2 \pi N  - \pi N \right] \\
I &= 2\pi N \, \frac{c \, \epsilon_0}{\delta} \,  |E_0|^2.
\end{align*}
This is the total energy density for the combined electromagnetic wave. The electric-only energy density is half of this.


%%%%%%

\newpage
\section{The Schr\"{o}dinger Equation in Spherical Coordinates}

\subsection{Separation of Variables}

The time-dependent Schr\"{o}dinger equation in three dimensions is simply
\begin{align*}
- \frac{\hbar^2}{2m} \laplacian \Psi + V \Psi = i \hbar \Psi.
\end{align*}
If the potential is not time-dependent we can separate out the time dependence as normal, using the stationary states (eigenstates) as a basis for any wavefunction in Hilbert space:
\begin{align*}
\Psi_n(\R, t) = \psi_n(\R) \; e^{i E_n \, t / \hbar},
\end{align*}
where $E_n$ is the energy of the state labeled $n$ and $\psi_n(\R)$ satisfies the time-independent Schr\"{o}dinger equation
\begin{align*}
- \frac{\hbar^2}{2m} \laplacian \psi_n + V \psi_n = E_n \psi.
\end{align*}
The Schr\"{o}dinger equation for any hydrogenic atom eigenstate written out in spherical coordinates (suppressing the eigenstate labeling, and using the reduced mass of the electron $\mu$) is
\begin{align}\label{eqn:schro_spherical}
-\frac{\hbar^2}{2\mu} \left[\frac{1}{r^2} \pdv{}{r} \left(r^2 \pdv{\psi}{r}\right) + \frac{1}{r^2 \sin{\theta}} \pdv{}{\theta} \left(\sin{\theta} \pdv{\psi}{\theta}\right) + \frac{1}{r^2 \sin^2{\theta}} \pdv[2]{\psi}{\phi} \right] + V(r)\,\psi = E\psi.
\end{align}
The lack of mixed derivatives indicates that we should look for a separable solution:
\begin{align*}
\psi(\R) = R(r) Y(\theta, \phi).
\end{align*}
Plug this back into \eqref{eqn:schro_spherical}:
\begin{align*}
&-\frac{\hbar^2}{2\mu} \left[\frac{1}{r^2} \pdv{}{r} \left(r^2 \, \pdv{RY}{r}\right) + \frac{1}{r^2 \sin{\theta}} \pdv{}{\theta} \left(\sin{\theta} \pdv{RY}{\theta}\right) + \frac{1}{r^2 \sin^2{\theta}} \pdv[2]{RY}{\phi} \right] + V(r) \, RY = E \, RY \\
&\left[\frac{1}{R} \pdv{}{r} \left(r^2 \, \pdv{R}{r}\right) + \frac{1}{Y}\frac{1}{\sin{\theta}} \pdv{}{\theta} \left(\sin{\theta} \pdv{Y}{\theta}\right) + \frac{1}{Y} \frac{1}{\sin^2{\theta}} \pdv[2]{Y}{\phi} \right] - \frac{2\mu \, r^2}{\hbar^2} \left(V(r) - E\right) = 0 \\
&\left[\frac{1}{R}\pdv{}{r} \left(r^2 \, \pdv{R}{r}\right) - \frac{2\mu \, r^2}{\hbar^2} \left[V(r) - E\right] \right] = -\frac{1}{Y}\left[\frac{1}{\sin{\theta}} \pdv{}{\theta} \left(\sin{\theta} \pdv{Y}{\theta}\right) + \frac{1}{\sin^2{\theta}} \pdv[2]{Y}{\phi} \right].
\end{align*}
Since the left and right hand sides of this equation depend separately on $r$ and $(\theta, \phi)$ respectively, they must both be equal to constants. We will call this constant $l(l+1)$. Then we have two equations: one for the ``spherical'' part of the wavefunction $Y$, and another for the ``radial'' part of the wavefunction $R$.
\begin{align}
\label{eqn:schro_radial}
\frac{1}{R} \dv{r} \left(r^2 \, \dv{R}{r}\right) - \frac{2\mu \, r^2}{\hbar^2} \left[V(r) - E\right] &= l(l+1) \\
\label{eqn:schro_angular}
\frac{1}{\sin{\theta}} \pdv{\theta} \left(\sin{\theta} \pdv{Y}{\theta}\right) + \frac{1}{\sin^2{\theta}} \pdv[2]{Y}{\phi} &= -l(l+1) \, Y. 
\end{align}

We will find that for the hydrogen bound states that every label $n$ will actually consist of a set of three integers, so the stationary bound states will be labeled $\psi_{nlm}$. The positive energy ``Coulomb'' states are labeled by their wavenumber $k$ and an integer $l$, $\psi_{kl}$.

\subsubsection{Angular Solution: Spherical Harmonics}

The solutions to \eqref{eqn:schro_angular} are the spherical harmonics.

\subsubsection{Radial Solution: No Potentials}

If there is no potential, the radial equation reduces to
\begin{align*}
\dv{r} \left(r^2 \, \dv{R}{r}\right) + \frac{2\mu \, r^2}{\hbar^2} E R - l(l+1) \, R &= 0
\end{align*}
To simplify the differential equation, we will instead solve for $u(r) = r R(r)$. Then we have
\begin{align*}
\dv{R}{r} &= \dv{\left(r^{-1} u\right)}{r} = -\frac{1}{r^2} u + \frac{1}{r} \dv{u}{r} \\
\dv{r} \left(r^2 \dv{R}{r}\right) &= \dv{r} \left(-u + r \dv{u}{r}\right) \\
&= - \dv{u}{r} + \dv{u}{r} + r \dv[2]{u}{r} \\
\dv{r} \left(r^2 \dv{R}{r}\right) &= r \dv[2]{u}{r}.
\end{align*}
Then we can rewrite the radial equation in terms of $u$:
\begin{align*}
r \dv[2]{u}{r} + \frac{2\mu \, r^2}{\hbar^2} E \frac{u}{r} - l(l+1) \frac{u}{r} &= 0.
\end{align*}
Identify $2 \mu E/\hbar^2$ as $k^2$, the squared free-space wavenumber of the electron. Then
\begin{align*}
r \dv[2]{u}{r} + k^2 r u - l(l+1) \frac{u}{r} &= 0 \\
\dv[2]{u}{r} + \left[k^2 - \frac{l(l+1)}{r^2} \right] \, u &= 0 \\
\dv[2]{u}{\rho} + \left[1 - \frac{l(l+1)}{\rho^2} \right] \, u &= 0,
\end{align*}
where $\rho \equiv kr$. The solutions are given by the spherical Bessel and Neumann functions ($j_l$ and $n_l$, respectively) times the radial coordinate, indexed by $l$:
\begin{align*}
j_l(\rho) &\equiv (-\rho)^l \left(\frac{1}{\rho} \dv{\rho}\right)^l \frac{\sin \rho}{\rho} \\
n_l(\rho) &\equiv (-\rho)^l \left(\frac{1}{\rho} \dv{\rho}\right)^l \frac{\cos \rho}{\rho}.
\end{align*}
Neumann functions have a singularity at the origin, so we must choose only the Bessel functions to form the solution basis. The full solution is
\begin{align*}
u(r) &= A \, r \, j_l(kr) \\
R(r) &= A \, j_l(kr) \\
\psi(r, \theta, \phi) &= A \, j_l(kr) \, Y_l^m\left(\theta, \phi \right).
\end{align*}

\subsection{Hydrogenic Radial Solutions}

The potential for Hydrogen-like atoms is the Coulomb potential,
\begin{align*}
V(\R) = - \frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r},
\end{align*}
where $Z$ is the number of protons in the nucleus of the atom.

\subsubsection{Bound States (Negative Energy)}

\subsubsection{Coulomb States (Positive Energy)}

The radial equation is
\begin{align*}
\dv{r} \left(r^2 \, \dv{R}{r}\right) + \frac{2\mu \, r^2}{\hbar^2} \left[\frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + E\right] R - l(l+1) \, R &= 0.
\end{align*}
To simplify the differential equation, we will instead solve for $u(r) = r R(r)$. Then we have
\begin{align*}
\dv{R}{r} &= \dv{\left(r^{-1} u\right)}{r} = -\frac{1}{r^2} u + \frac{1}{r} \dv{u}{r} \\
\dv{r} \left(r^2 \dv{R}{r}\right) &= \dv{r} \left(-u + r \dv{u}{r}\right) \\
&= - \dv{u}{r} + \dv{u}{r} + r \dv[2]{u}{r} \\
\dv{r} \left(r^2 \dv{R}{r}\right) &= r \dv[2]{u}{r}.
\end{align*}
Then we can rewrite the radial equation in terms of $u$:
\begin{align*}
r \dv[2]{u}{r} + \frac{2\mu \, r^2}{\hbar^2} \left[\frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + E\right] \frac{u}{r} - l(l+1) \frac{u}{r} &= 0 \\
\dv[2]{u}{r} + \frac{2\mu}{\hbar^2} \left[\frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + E\right] u - \frac{l(l+1)}{r^2} u &= 0 \\
\dv[2]{u}{r} + \left[\frac{2\mu}{\hbar^2} \frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + \frac{2\mu E}{\hbar^2}\right] u - \frac{l(l+1)}{r^2} u &= 0.
\end{align*}
Now note that $2 \mu E / \hbar^2 = k^2$, the square of the wavenumber of a free electron with energy $E$. Substitute this in, and combine it with $r$ to form $\rho = kr$, the amount of phase acquired over distance $r$:
\begin{align*}
\dv[2]{u}{r} + \left[\frac{k^2}{E} \frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + k^2 \right] u - \frac{l(l+1)}{r^2} u &= 0 \\
\frac{1}{k^2}\dv[2]{u}{r} + \left[\frac{1}{E} \frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{r} + 1 \right] u - \frac{l(l+1)}{(kr)^2} u &= 0 \\
\dv[2]{u}{\rho} + \left[1 + \frac{2\mu}{\hbar^2 k} \frac{Z e^2}{4 \pi \epsilon_0} \frac{1}{kr} - \frac{l(l+1)}{\rho^2}\right] u  &= 0 \\
\dv[2]{u}{\rho} + \left[1 - \frac{2\eta}{\rho} - \frac{l(l+1)}{\rho^2}\right] u  &= 0, \qquad \eta =  -\frac{Z e^2 \mu}{4 \pi \epsilon_0 \hbar^2 k}
\end{align*}
The solutions to this differential equation are given by Abramowitz and Stegun \cite{Abramowitz1965, NIST:DLMF}. Since it is second-order there are two solutions, but the second (``irregular'') solution is not physical [not really sure why, I think it has a singularity at $r=0$], so we set it's coefficient to zero. The physically relevant solution is
\begin{align*}
u(\rho) &= C_l(\eta) \, \rho^{l+1} \, e^{-i\rho} \; M(l+1-i\eta, 2l+2; 2i\rho) \\
R(\rho) &= C_l(\eta) \, \rho^{l+1} \, \frac{e^{-i\rho}}{r} \; M(l+1-i\eta, 2l+2; 2ikr), \\
C_l(\eta) &= \frac{2^l e^{-\pi \eta / 2} \left|\Gamma\left(l + 1 + i\eta\right)\right|}{\left(2l+1\right)!},
\end{align*}
where $C_l(\eta)$ is a normalizing factor, and $M(a, b; x)$ is the confluent hypergeometric function:
\begin{align*}
M(a, b; x) \equiv \sum_{n=0}^{\infty} \frac{a^{(n)} \, x^n}{b^{(n)} \, n!},
\end{align*}
where $a^{n} = a (a+1) (a+2) \cdots (a+n-1)$ is a rising factorial. $C_l$ can also be expressed using a recurrence relation, with
\begin{align*}
C_l(\eta) &= \frac{\sqrt{l^2 + \eta^2}}{l \left(2l + 1\right)} \, C_{l-1}(\eta) \\
C_0(\eta) &= \sqrt{\frac{2 \pi \eta}{e^{2 \pi \eta} - 1}}
\end{align*}

%%%%%%

\newpage
\section{Simulation Implementation}\label{sec:cylindrical_slices}

In this section we will begin attacking the numerical parts of the problem. We will define a ``mesh", a grid of points that we can do numerical calculations on, and develop techniques for performing those calculations accurately and efficiently.

\subsection{Cylindrical-Slice Mesh}\label{sec:cylindrical_slices}

\subsubsection{The Mesh}\label{sec:cylindrical_mesh}
In this simulation we discretize space into a cylindrically symmetric mesh of points. We choose to enforce azimuthal symmetry and consider only a single $\phi$-slice of the mesh, which forces $m=0$. The mesh therefore has two coordinates, $\rho$ and $z$:
\begin{align}
&\rho \rightarrow \rho_j = \left(j + \frac{1}{2}\right) \, \Delta \rho \qquad j = 0, 1, 2, \cdots, N_{\rho} \nonumber \\
&z \rightarrow z_k = \left(k - \frac{N_z}{2}\right) \, \Delta z \qquad k = 0, 1, 2, \cdots, N_{z}. \nonumber
\end{align}
In these notes we will refer to ``the mesh'', ``a mesh'', and ``the $g$ mesh''. ``The mesh'' refers to the physical locations of the points, so that a function may be ``defined on the mesh'', for example. ``A mesh'' is some field that has a value at every point on the mesh. ``The $g$ mesh'' refers to the particular mesh that represents the wavefunction on the mesh (the notation will become clear in the next section). For example, the result of applying the Hamiltonian to the $g$ mesh produces a mesh that we could call $Hg$.

%%%

\subsubsection{The Wavefunction and Inner Products}
The next step is to discretize the wavefunction. However, to simplify our calculations we will first make the transformation $\Psi \equiv g/\sqrt{2 \pi \rho}$. To see why this is helpful, consider the inner product of two wavefunctions $\Psi_1(\rho, z)$ and $\Psi_2(\rho, z)$ on the mesh:
\begin{align*}
\braket{\Psi_1}{\Psi_2} &= \int_V \Psi^*_1(\R) \, \Psi^{}_2(\R) \, dV \\
&= \int_{0}^{2\pi} \int_{-\infty}^{\infty} \int_{0}^{\infty} \Psi^*_1(\rho, z) \, \Psi^{}_2(\rho, z) \, \rho \, d\rho \, dz \, d\phi \\
&= 2 \pi \int_{-\infty}^{\infty} \int_{0}^{\infty} \Psi^*_1(\rho, z) \, \Psi^{}_2(\rho, z) \, \rho \,  d\rho \, dz \\
&= 2 \pi \int_{-\infty}^{\infty} \int_{0}^{\infty} \frac{g^*_1(\rho, z)}{\sqrt{2 \pi \rho}} \, \frac{g^{}_2(\rho, z)}{\sqrt{2 \pi \rho}} \, \rho \, d\rho \, dz \\
&= \int_{-\infty}^{\infty} \int_{0}^{\infty} \, g^*_1(\rho, z) \, g^{}_2(\rho, z) \, d\rho \, dz \\
\braket{\Psi_1}{\Psi_2} &\rightarrow \sum_{jk} g^*_{1, \, jk} \, g^{}_{2, \, jk} \, \Delta \rho \, \Delta z \equiv \braket{g_1}{g_2}.
\end{align*}
We see that with this transformation the discretized inner product on the mesh is simply a sum over the element-wise product of the wavefunction's associated $g$ meshes (with one of them complex-conjugated). This transformation will also facilitate calculation of the derivatives in the Schr\"{o}dinger equation, as described in the next section. In fact, this method will work for any operator that can be defined as an operation on the $g$ mesh that returns a mesh, and thus works for expectation values of operators as well.

This works so well because the transformation factor is the square root of the Jacobian integrated over the symmetric variables (in this case $\phi$, which gives the $2\pi$). We are taking our initial 3-dimensional cylinder and warping it into a 2-dimensional rectangle which we will perform calculations on.

%%%

\subsubsection{The Hamiltonian}\label{sec:cylindrical_hamiltonian}
All time evolution in this simulation is performed by numerically integrating the Schr\"{o}dinger equation. To perform these calculations quickly we must find the Hamiltonian as a matrix operator acting on a ``flattened" $g$ mesh. The time-dependent Schr\"{o}dinger equation is
\begin{align}
i \hbar \pdv{\Psi}{t} &= H \Psi \nonumber \\
i \hbar \pdv{\Psi}{t} &= \left[-\frac{\hbar^2}{2m} \laplacian - \frac{k_e q^2}{r} - q z \, E(t)\right] \Psi.
\end{align}
Of the three terms on the right, only the Laplacian is nontrivial to implement numerically on a mesh (the other two can be evaluated at each point individually). Focus on that term, and write it in cylindrical coordinates:
\begin{align}
i\hbar\pdv{\Psi}{t} &= -\frac{\hbar^2}{2m} \laplacian \Psi + \cdots \nonumber \\
i\hbar\pdv{\Psi}{t} &= -\frac{\hbar^2}{2m} \left[\frac{1}{\rho} \pdv{\Psi}{\rho} + \pdv[2]{\Psi}{\rho} + \pdv[2]{\Psi}{z}\right] + \cdots.
\end{align}
Note the lack of an angular derivative, because we have already assumed angular symmetry (the derivative is zero). Now make the transformation $\Psi = g/\sqrt{2 \pi \rho}$ (note that this does nothing to the two terms in the Hamiltonian that we are not considering):
\begin{align}
\frac{1}{\sqrt{2\pi\rho}} \, i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \frac{1}{\sqrt{2\pi}} \left[\frac{1}{\rho} \pdv{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) + \pdv[2]{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) + \frac{1}{\sqrt{\rho}}\pdv[2]{g}{z}\right] + \cdots.
\end{align}
Now we will put this equation on the standard mesh. We use centered differences for the derivatives:
\begin{align}
\pdv[2]{g}{z} &\rightarrow \frac{g_{j, k+1} + g_{j, k-1} - 2g_{j,k}}{\Delta z^2} \nonumber \\
\pdv{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) &\rightarrow \frac{1}{2 \, \Delta \rho} \left( \frac{g_{j+1, k}}{\sqrt{(j+\frac{3}{2}) \Delta \rho}} - \frac{g_{j-1, k}}{\sqrt{(j-\frac{1}{2}) \Delta \rho}} \right) \nonumber \\
\pdv[2]{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) &\rightarrow  \frac{1}{\Delta \rho^2} \left( \frac{g_{j+1,k}}{\sqrt{(j+\frac{3}{2}) \Delta \rho}} + \frac{g_{j-1,k}}{\sqrt{(j-\frac{1}{2}) \Delta \rho}} - \frac{2g_{j,k}}{\sqrt{(j+\frac{1}{2}) \Delta \rho}}\right).
\end{align}
The $z$ kinetic energy component separates out cleanly:
\begin{align*}
K^{(z)} g_{jk} = -\frac{\hbar^2}{2m} \frac{1}{\Delta z^2} \left[g_{j, k+1} + g_{j, k-1} - 2g_{j,k}\right],
\end{align*}
where we now think of $K^{(z)}$ as an operator acting on $g$. The $\rho$ component can be simplified:
\begin{align*}
K^{(\rho)} g &= -\frac{\hbar^2}{2m} \left[ \frac{1}{\sqrt{\rho}} \pdv{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) + \sqrt{\rho}\pdv[2]{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) \right] \\
%
K^{(\rho)} g_{jk} &= -\frac{\hbar^2}{2m} \left[ \frac{1}{2 \, \Delta \rho \sqrt{(j+\frac{1}{2}) \Delta \rho}} \left( \frac{g_{j+1, k}}{\sqrt{(j+\frac{3}{2}) \Delta \rho}} - \frac{g_{j-1, k}}{\sqrt{\left(j-\frac{1}{2}\right) \Delta \rho}} \right) \right. \\ &\qquad \left. + \sqrt{\left(j+\frac{1}{2}\right) \Delta \rho} \, \frac{1}{\Delta \rho^2} \left( \frac{g_{j+1,k}}{\sqrt{\left(j+\frac{3}{2}\right) \Delta \rho}} + \frac{g_{j-1,k}}{\sqrt{\left(j-\frac{1}{2}\right) \Delta \rho}} - \frac{2g_{j,k}}{\sqrt{(j+\frac{1}{2}) \Delta \rho}}\right) \right] \\
%
&= -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2} \left[ \frac{1}{2 \sqrt{j+\frac{1}{2}}} \left( \frac{g_{j+1, k}}{\sqrt{j+\frac{3}{2}}} - \frac{g_{j-1, k}}{\sqrt{j-\frac{1}{2}}} \right) + \sqrt{j+\frac{1}{2}} \, \left( \frac{g_{j+1,k}}{\sqrt{j+\frac{3}{2}}} + \frac{g_{j-1,k}}{\sqrt{j-\frac{1}{2}}} - \frac{2g_{j,k}}{\sqrt{j+\frac{1}{2}}}\right) \right] \\
%
&= -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2} \left[ \left( \frac{\frac{1}{2}}{\sqrt{\left(j+\frac{1}{2}\right)\left(j+\frac{3}{2}\right)}} + \frac{\sqrt{j+\frac{1}{2}}}{\sqrt{\left(j+\frac{3}{2}\right)}} \right) g_{j+1, k} \right. \\ & \left. \qquad\qquad\qquad + \left( \frac{-\frac{1}{2}}{\sqrt{\left(j+\frac{1}{2}\right)\left(j-\frac{1}{2}\right)}} + \frac{\sqrt{j+\frac{1}{2}}}{\sqrt{\left(j-\frac{1}{2}\right)}} \right) g_{j-1, k} - 2 \, g_{j,k} \right] \displaybreak \\
&= -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2} \left[ \left( \frac{\frac{1}{2}}{\sqrt{\left(j+\frac{1}{2}\right)\left(j+\frac{3}{2}\right)}} + \frac{j+\frac{1}{2}}{\sqrt{\left(j+\frac{3}{2}\right)\left(j+\frac{1}{2}\right)}} \right) g_{j+1, k} \right. \\ & \left. \qquad\qquad\qquad + \left( \frac{-\frac{1}{2}}{\sqrt{\left(j+\frac{1}{2}\right)\left(j-\frac{1}{2}\right)}} + \frac{j+\frac{1}{2}}{\sqrt{\left(j-\frac{1}{2}\right)\left(j+\frac{1}{2}\right)}} \right) g_{j-1, k} - 2 \, g_{j,k} \right] \\
&= -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2} \left[ \frac{j+1}{\sqrt{\left(j+\frac{1}{2}\right)\left(j+\frac{3}{2}\right)}} \, g_{j+1, k}+  \frac{j}{\sqrt{\left(j-\frac{1}{2}\right)\left(j+\frac{1}{2}\right)}} \, g_{j-1, k} - 2 \, g_{j,k} \right] \\
%
K^{(\rho)} g_{jk} &= -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2} \left[ c_{j+1} \, g_{j+1, k} +  c_{j} \, g_{j-1, k} - 2 \, g_{j,k} \right]
\end{align*}
where
\begin{align*}
c_j = \frac{j}{\sqrt{j^2-\frac{1}{4}}}.
\end{align*}
In matrix form with $g_{jk}$ flattened into a vector along the $j$ index, $K^{(\rho)}$ is
\begin{align*}
K^{(\rho)}g^{(\rho)} = -\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2}\begin{bmatrix}
-2 & c_1 & 0 & 0 & \ddots \\
c_1 & -2 & c_2 & 0  & \ddots \\
0 & c_2 & -2 & c_3  & \ddots \\
0 & 0 & c_3 & -2 & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix}
\begin{bmatrix}
g_{00} \\
g_{10} \\
g_{20} \\
g_{30} \\
\vdots \\
\end{bmatrix}.
\end{align*}
Note that the matrix operation is tridiagonal. If we flatten $g_{jk}$ along the $k$ index instead, we see that $K^{(z)}$ is also tridiagonal:
\begin{align*}
K^{(z)}g^{(z)} = -\frac{\hbar^2}{2m} \frac{1}{\Delta z^2}\begin{bmatrix}
-2 & 1 & 0 & 0 & \ddots \\
1 & -2 & 1 & 0  & \ddots \\
0 & 1 & -2 & 1  & \ddots \\
0 & 0 & 1 & -2 & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix}
\begin{bmatrix}
g_{00} \\
g_{01} \\
g_{02} \\
g_{03} \\
\vdots \\
\end{bmatrix}.
\end{align*}
There are three important points about these matrix representations. First, the $c_j$ repeat in a cycle as we switch ``rows'' of the mesh. Additionally, certain off-diagonal elements are zero, namely at the boundaries of the mesh (if these are not zero, we would have periodic boundary conditions). Similarly, there is no modification of the terms to account for the boundaries having an ``empty'' point on their other side (note the first row of the matrix in particular). This is because we have effectively embedded our mesh in a slightly larger mesh that has Dirichlet ($g=0$) boundary conditions on it (this is the main point of making the $g$ transformation).

To get the full Hamiltonian we must reincorporate the potential energy terms. We do this by putting half of each term into each component of the Hamiltonian. If we call the potential (Coulomb and external combined) at each point on the grid $W_{jk}$, we see that this part of the operator is simply a diagonal matrix when we operate on a flattened $g$ mesh:
\begin{align*}
Hg &= \Hp g^{(\rho)} + \Hz g^{(z)} = \left[K^{(\rho)} + \frac{1}{2} W^{(\rho)}\right] g^{(\rho)} + \left[K^{(z)} + \frac{1}{2} W^{(z)}\right] g^{(z)} \\
Hg &= \left(-\frac{\hbar^2}{2m} \frac{1}{\Delta \rho^2}\begin{bmatrix}
-2 & c_1 & 0 & 0 & \ddots \\
c_1 & -2 & c_2 & 0  & \ddots \\
0 & c_2 & -2 & c_3  & \ddots \\
0 & 0 & c_3 & -2 & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix}
+
\frac{1}{2}\begin{bmatrix}
W_{00} & 0 & 0 & 0 & \ddots \\
0 & W_{10} & 0 & 0 & \ddots \\
0 & 0 & W_{20} & 0 & \ddots \\
0 & 0 & 0 & W_{30} & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix} \right)
\begin{bmatrix}
g_{00} \\
g_{10} \\
g_{20} \\
g_{30} \\
\vdots \\
\end{bmatrix} \\
&\quad +\left(-\frac{\hbar^2}{2m} \frac{1}{\Delta z^2}\begin{bmatrix}
-2 & 1 & 0 & 0 & \ddots \\
1 & -2 & 1 & 0  & \ddots \\
0 & 1 & -2 & 1  & \ddots \\
0 & 0 & 1 & -2 & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix}
+
\frac{1}{2}\begin{bmatrix}
W_{00} & 0 & 0 & 0 & \ddots \\
0 & W_{01} & 0 & 0 & \ddots \\
0 & 0 & W_{02} & 0 & \ddots \\
0 & 0 & 0 & W_{03} & \ddots \\
\ddots & \ddots & \ddots & \ddots & \ddots \\
\end{bmatrix} \right)
\begin{bmatrix}
g_{00} \\
g_{01} \\
g_{02} \\
g_{03} \\
\vdots \\
\end{bmatrix}.
\end{align*}
Note that the result is a $g$ mesh, so we must ``wrap up'' the $g$ vectors before we add them together. Using the three different representations of $g$ (unwrapped in $\rho$, unwrapped in $z$, and the two-dimensional mesh itself) to ensure that the matrix operators are always tridiagonal is the key to the speed of the simulation.

%%%

\subsubsection{Time Evolution Operator}\label{sec:cylindrical_time_evolution}
Now that we have the Hamiltonian we can think about the time evolution operator. We think of the time evolution as occurring in discrete time steps $\Delta t$. Then, using the unit operator $I$ and defining $\tau \equiv \Delta t / 2 \hbar$, time evolution can be performed using
\begin{align}\label{eqn:time_evolution_operator}
g(t + \Delta t) = \left[I + i \tau \Hp\right]^{-1} \, \left[I - i \tau \Hz\right] \, \left[I + i \tau \Hz\right]^{-1} \, \left[I - i \tau \Hp\right] g(t),
\end{align}
where $g(t)$ must be flattened in the appropriate direction before each matrix multiplication. If $\tau$ is sufficiently small we can expand the inverses in a power series:
\begin{align*}
g(t + \Delta t) &= \left[I - i \tau \Hp - \tau^2 \left(\Hp\right)^2 + \cdots \right] \, \left[I - i \tau \Hz\right] \\&\qquad \left[I - i \tau \Hz - \tau^2 \left(\Hz\right)^2 + \cdots \right] \, \left[I - i \tau \Hp\right] g(t) \\
%
&= \left[I - i \tau (\Hp + 2\Hz) - \tau^2 \left(\left(\Hp\right)^2 + \Hp \Hz\right)  + \cdots \right] \\&\qquad \left[I - i \tau \Hz - \tau^2 \left(\Hz\right)^2 + \cdots \right] \, \left[I - i \tau \Hp\right] g(t) \\
%
&= \left[I - i \tau (\Hp + 2\Hz) - \tau^2 \left(\left(\Hp\right)^2 + 2\Hp \Hz + 2\left(\Hz\right)^2\right) + \cdots \right] \\&\qquad \left[I - i \tau \Hp\right] g(t) \\
%
&= \left[I - i \tau (2\Hp + 2\Hz) - \tau^2 \left(2 \left(\Hp\right)^2 + 2\Hp \Hz + 2 \Hz \Hp + 2\left(\Hz\right)^2\right) + \cdots \right] g(t) \\
&= \left[I - 2 i \tau (\Hp + \Hz) - 2 \tau^2 \left(\Hp + \Hz\right)^2 + \cdots \right] g(t).
\end{align*}
This agrees with the Taylor expansion of the time evolution operator through second order in $\Delta t$:
\begin{align*}
g(t + \Delta t) &= \exp\left[{-i \frac{\Delta t}{\hbar} \left(\Hp + \Hz\right)}\right] g(t) \\
g(t + \Delta t) &= \left[I - i\frac{\Delta t}{\hbar} \left(\Hp + \Hz\right) - \frac{1}{2} \left(\frac{\Delta t}{\hbar}\right)^2\left(\Hp + \Hz\right)^2 + \cdots\right] g(t).
\end{align*}
Although this does imply a more direct (and faster) method of time evolution where we simply perform point-wise multiplication on the mesh by the time evolution operator or its Taylor expansion, these methods are not suitable for numerical calculations because they involve computing the squares (or even higher powers) of large matrices, which both scales poorly and tends to cause overflow errors. Equation \eqref{eqn:time_evolution_operator} deals with matrices in first order only, but is slower than direct multiplication due to the required multiplication by matrix inverses.

Note that $z$ and $\rho$ can be swapped freely as long as the structure of the four-part matrix operation is preserved. The four steps can be thought of as, in order:
\begin{enumerate}
	\item Evolve \emph{forwards} by $+\Delta t/2$ using direction 1,
	\item Evolve \emph{backwards} by $-\Delta t/2$ using direction 2,
	\item Evolve \emph{forwards} by $+\Delta t/2$ using direction 2,
	\item Evolve \emph{backwards} by $-\Delta t/2$ using direction 1.
\end{enumerate}
Evolving backwards in time by a negative time step is, of course, the same as evolving forwards in time.


%%%

\subsubsection{Probability Current}\label{sec:cylindrical_probability_current}
The probability current is defined as
\begin{align*}
\mathbf{J} = \frac{\hbar}{2m i} \left(\Psi^* \nabla \Psi -\Psi \nabla \Psi^* \right).
\end{align*}
Break this into components:
\begin{align*}
J^{(z)}  &= \frac{\hbar}{2m i} \left(\Psi^* \pdv{\Psi}{z} - \Psi \pdv{\Psi^*}{z} \right) \\
J^{(\rho)}  &= \frac{\hbar}{2m i} \left(\Psi^* \pdv{\Psi}{\rho} - \Psi \pdv{\Psi^*}{\rho} \right).
\end{align*}
Using the same finite difference scheme as before, $J^{(z)}$ is simple:
\begin{align*}
J^{(z)} &= \frac{\hbar}{2m i} \frac{1}{2\pi \rho}\left[g^* \pdv{g}{z} - g \pdv{g^*}{z} \right] \\
%
J^{(z)}_{jk} &= \frac{\hbar}{2m i} \frac{1}{2\pi \left(j+\frac{1}{2}\right) \Delta \rho}\left[g^*_{jk} \left(\frac{g^{}_{j,k+1} - g^{}_{j, k-1}}{2 \Delta z}\right) - g^{}_{jk} \left(\frac{g^{*}_{j,k+1} - g^{*}_{j, k-1}}{2 \Delta z}\right) \right] \\
%
J^{(z)}_{jk} &= \frac{\hbar}{2m i} \frac{1}{2\pi} \frac{1}{2\Delta \rho \, \Delta z}\left[g^*_{jk} \, \left(j+\frac{1}{2}\right) \left(g^{}_{j,k+1} - g^{}_{j, k-1}\right) - g^{}_{jk} \, \left(j+\frac{1}{2}\right)\left(g^{*}_{j,k+1} - g^{*}_{j, k-1}\right) \right] \\
%
J^{(z)}_{jk} &= \frac{\hbar}{2m} \frac{1}{2\pi} \frac{1}{\Delta \rho \, \Delta z} \, \operatorname{Im}\left[g^*_{jk} \, \frac{1}{j + \frac{1}{2}} \left(g^{}_{j,k+1} - g^{}_{j, k-1}\right)\right],
\end{align*}
where we have noted that the difference of a number and its complex conjugate is twice the imaginary part. Also note that unlike the kinetic energy matrix operator, the coefficient for the operator in the $k$-direction depends on the index $j$. $J^{(\rho)}$ is slightly more complicated:
\begin{align*}
J^{(\rho)} &= \frac{\hbar}{2m i} \frac{1}{2\pi \sqrt{\rho}}\left[g^* \pdv{}{\rho}\left(\frac{g}{\sqrt{\rho}}\right) - g \pdv{}{\rho}\left(\frac{g^*}{\sqrt{\rho}}\right) \right] \\
%
J^{(\rho)}_{jk} &= \frac{\hbar}{2mi} \, \frac{1}{2 \pi \sqrt{\left(j+\frac{1}{2}\right) \Delta \rho}} \left[g_{jk}^* \, \frac{1}{2 \, \Delta \rho} \left( \frac{g_{j+1, k}}{\sqrt{(j+\frac{3}{2}) \Delta \rho}} - \frac{g_{j-1, k}}{\sqrt{(j-\frac{1}{2}) \Delta \rho}} \right) \right. \\ &\left. \qquad\qquad\qquad - g_{jk}^{} \, \frac{1}{2 \, \Delta \rho} \left( \frac{g_{j+1, k}}{\sqrt{(j+\frac{3}{2}) \Delta \rho}} - \frac{g_{j-1, k}}{\sqrt{(j-\frac{1}{2}) \Delta \rho}} \right) \right] \\
%
J^{(\rho)}_{jk} &= \frac{\hbar}{2mi} \, \frac{1}{2 \pi} \frac{1}{2 \Delta \rho^2} \frac{1}{\sqrt{j+\frac{1}{2}}} \, \left[g_{jk}^* \, \left( \frac{g_{j+1, k}}{\sqrt{j+\frac{3}{2}}} - \frac{g_{j-1, k}}{\sqrt{j-\frac{1}{2}}} \right) - g_{jk}^{} \, \left( \frac{g_{j+1, k}}{\sqrt{j+\frac{3}{2}}} - \frac{g_{j-1, k}}{\sqrt{-\frac{1}{2}}} \right) \right] \\
%
J^{(\rho)}_{jk} &= \frac{\hbar}{2m} \, \frac{1}{2 \pi} \frac{1}{\Delta \rho^2} \, \operatorname{Im} \left[g_{jk}^* \, \left( d_{j+1} \, g_{j+1, k} - d_j \, g_{j-1, k} \right) \right],
\end{align*}
where
\begin{align*}
d_j = \frac{1}{\sqrt{j^2 - \frac{1}{4}}}.
\end{align*}


\subsection{Spherical-Slice Mesh}\label{sec:spherical_slices}

Although the cylindrical-slice mesh was easy to work with, it does not have the same natural symmetry of the problem - namely, spherical. In particular, a lot of mesh is ``wasted" in the corners far from the nucleus, where the distance to the nucleus is larger than the straight-line bounds of the mesh and is thus untrustworthy. To solve this problem, we will instead use a mesh that is a single $\phi$ slice of a sphere. This section should be considered supplementary to the method described in Section \ref{sec:cylindrical_slices} - simply replace the necessary results with results from this section to switch which kind of mesh you're working on.

\subsubsection{The Mesh and Wavefunction}\label{sec:spherical_mesh}

We discretize space with
\begin{align}
&r \rightarrow r_j = \left(j + \frac{1}{2}\right) \, \Delta r \qquad j = 0, 1, 2, \cdots, N_{r} \nonumber \\
&\theta \rightarrow \theta_k = \left(k + \frac{1}{2}\right) \, \Delta \theta \qquad k = 0, 1, 2, \cdots, N_{\theta} \qquad \Delta\theta = \frac{\pi}{N_{\theta} - 1} \nonumber
\end{align}
We will also plan on making the transformation
\begin{align}\label{eqn:g_spherical}
g \equiv \sqrt{2 \pi r^2 \sin{\theta}} \, \Psi \nonumber \\
\Psi = \frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}.
\end{align}
which provides the desired form for the inner product:
\begin{align*}
\braket{\Psi_1}{\Psi_2} &= \int_V \Psi^*_1(\R) \, \Psi^{}_2(\R) \, dV \\
&= \int_{0}^{2\pi} \int_{0}^{\pi} \int_{0}^{\infty} \Psi^*_1(r, \theta) \, \Psi^{}_2(r, \theta) \, r^2 \sin{\theta} \, dr \, d\theta \, d\phi \\
&= 2\pi \int_{0}^{\pi} \int_{0}^{\infty} \Psi^*_1(r, \theta) \, \Psi^{}_2(r, \theta) \, r^2 \sin{\theta} \, dr \, d\theta \\
&= 2\pi \int_{0}^{\pi} \int_{0}^{\infty} \frac{g^*_1(r, \theta)}{\sqrt{2 \pi r^2 \sin{\theta}}} \, \frac{g^{}_2(r, \theta)}{\sqrt{2 \pi r^2 \sin{\theta}}} \, r^2 \sin{\theta} \, dr \, d\theta \\
&= \int_{0}^{\pi} \int_{0}^{\infty} g^*_1(r, \theta) \, g^{}_2(r, \theta) \, dr \, d\theta \\
\braket{\Psi_1}{\Psi_2} &\rightarrow \sum_{jk} g^*_{1, \, jk} \, g^{}_{2, \, jk} \, \Delta r \, \Delta \theta \equiv \braket{g_1}{g_2}.
\end{align*}

\subsubsection{Kinetic Energy}\label{sec:spherical_kinetic_energy}

The time evolution is controlled by:
\begin{align*}
i \hbar \pdv{\Psi}{t} = H\Psi = -\frac{\hbar^2}{2m} \laplacian{\Psi} + \cdots
\end{align*}
The $\phi$-symmetric laplacian in spherical coordinates is typically presented as
\begin{align}\label{eqn:sph_laplacian_1}
\laplacian{\Psi} = \frac{1}{r^2} \pdv{}{r} \left(r^2 \pdv{\Psi}{r}\right) + \frac{1}{r^2 \sin{\theta}}\pdv{}{\theta} \left(\sin{\theta} \,  \pdv{\Psi}{\theta}\right).
\end{align}
This form is not particularly useful since it contains compound derivatives. There are two alternate ways to write the $r$ term:
\begin{align*}
\frac{1}{r^2} \pdv{}{r} \left(r^2 \pdv{\Psi}{r}\right) = \frac{1}{r^2} \left(2r\pdv{\Psi}{r} + r^2 \pdv[2]{\Psi}{r}\right) = \frac{2}{r^2} \pdv{\Psi}{r} + \pdv[2]{\Psi}{r},
\end{align*}
or
\begin{align}\label{eqn:sph_laplacian_r_replacement}
\frac{1}{r} \pdv[2]{}{r} \left(r \, \Psi\right) = \frac{1}{r} \pdv{}{r} \left(\Psi + r \pdv{\Psi}{r}\right) = \frac{1}{r} \left(2\pdv{\Psi}{r} + r \pdv[2]{\Psi}{r}\right) = \frac{2}{r} \pdv{\Psi}{r} + \pdv[2]{\Psi}{r}.
\end{align}
We will use \eqref{eqn:sph_laplacian_r_replacement}, since it contains only a single second derivative. We can also remove the compound derivative from the $\theta$ term:
\begin{align}\label{eqn:sph_laplacian_theta_replacement}
\frac{1}{r^2 \sin{\theta}} \pdv{}{\theta} \left(\sin{\theta} \, \pdv{\Psi}{\theta}\right) = \frac{1}{r^2 \sin{\theta}} \left(\cos{\theta} \, \pdv{\Psi}{\theta} + \sin{\theta} \, \pdv[2]{\Psi}{\theta}\right) = \frac{1}{r^2} \left(\cot{\theta} \, \pdv{\Psi}{\theta} + \pdv[2]{\Psi}{\theta}\right)
\end{align}
Substituting \eqref{eqn:sph_laplacian_r_replacement} and \eqref{eqn:sph_laplacian_theta_replacement} into \eqref{eqn:sph_laplacian_1}, we have
\begin{align}\label{eqn:sph_laplacian_2}
\laplacian{\Psi} = \frac{1}{r} \pdv[2]{}{r} \left(r \, \Psi\right) + \frac{1}{r^2} \left(\cot{\theta} \, \pdv{\Psi}{\theta} + \pdv[2]{\Psi}{\theta}\right).
\end{align}
The next step is to apply the transformation \eqref{eqn:g_spherical} to \eqref{eqn:sph_laplacian_2}:
\begin{align}\label{eqn:sph_laplacian_g}
\laplacian{\Psi} &= \frac{1}{r} \pdv[2]{}{r} \left(r \, \frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) + \frac{1}{r^2} \left[\cot{\theta} \, \pdv{}{\theta}\left(\frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) + \pdv[2]{}{\theta}\left(\frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right)\right] \nonumber \\
%
i \hbar \frac{1}{\sqrt{2 \pi r^2 \sin\theta}} \pdv{g}{t} &= \frac{1}{r} \pdv[2]{}{r} \left(r \, \frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) + \frac{1}{r^2} \left[\cot{\theta} \, \pdv{}{\theta}\left(\frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) + \pdv[2]{}{\theta}\left(\frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right)\right] + \cdots \nonumber \\
%
i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \sqrt{\sin{\theta}} \left[\pdv[2]{}{r} \left(\frac{g}{\sqrt{\sin{\theta}}}\right) + \frac{\cot{\theta}}{r^2} \, \pdv{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right) + \frac{1}{r^2}\pdv[2]{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right)\right] + \cdots \nonumber \\
i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \left[\pdv[2]{g}{r} +\frac{\cot{\theta} \sqrt{\sin{\theta}}}{r^2} \, \pdv{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right) + \frac{\sqrt{\sin{\theta}}}{r^2}\pdv[2]{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right)\right] + \cdots.
\end{align}
We will now replace all of the derivatives in \eqref{eqn:sph_laplacian_g} with finite differences. Just like in the cylindrical case, we use centered finite differences:
\begin{align}\label{eqn:sph_finite_differences}
\pdv[2]{g}{r} &\rightarrow \frac{g_{j+1, k} + g_{j-1, k} - 2g_{j,k}}{\left(\Delta r\right)^2} \\
%
\frac{\cot{\theta} \sqrt{\sin{\theta}}}{r^2}\pdv{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right) &\rightarrow 
\frac{\cot((k+\frac{1}{2}) \Delta \theta) \sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{2 \, \Delta \theta \, \left[\left(j+\frac{1}{2}\right) \Delta r\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} - \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}}   \right] \nonumber \\
%
\frac{\sqrt{\sin{\theta}}}{r^2}\pdv[2]{}{\theta}\left(\frac{g}{\sqrt{\sin{\theta}}}\right) &\rightarrow  
\frac{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} + \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}} - \frac{2g_{j, k}}{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}  \right] \nonumber
\end{align}
Apply the replacements \eqref{eqn:sph_finite_differences} to \eqref{eqn:sph_laplacian_g}:
\begin{align}
i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \left\lbrace      \frac{g_{j+1, k} + g_{j-1, k} - 2g_{j,k}}{\left(\Delta r\right)^2} \right. \nonumber \\
&\quad + \frac{\cot((k+\frac{1}{2}) \Delta \theta) \sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{2 \, \Delta \theta \, \left[\left(j+\frac{1}{2}\right) \Delta r\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} - \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}}   \right] \nonumber \\
&\quad \left.   + \frac{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} + \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}} - \frac{2g_{j, k}}{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}  \right]        \right\rbrace + \cdots \nonumber \\
%%%%%
i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \left\lbrace      \frac{g_{j+1, k} + g_{j-1, k} - 2g_{j,k}}{\left(\Delta r\right)^2} \right. \nonumber \\
&\quad + \frac{\cot((k+\frac{1}{2}) \Delta \theta) \, \Delta\theta}{2}   \frac{ \sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} - \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}}   \right] \nonumber \\
&\quad \left.   + \frac{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \left[  \frac{g_{j, k+1}}{\sqrt{\sin((k+\frac{3}{2}) \Delta \theta)}} + \frac{g_{j, k-1}}{\sqrt{\sin((k-\frac{1}{2}) \Delta \theta)}} - \frac{2g_{j, k}}{\sqrt{\sin((k+\frac{1}{2}) \Delta \theta)}}  \right]        \right\rbrace + \cdots \nonumber \\
%%%%%
i \hbar \pdv{g}{t} &= -\frac{\hbar^2}{2m} \left\lbrace      \frac{g_{j+1, k} + g_{j-1, k} - 2g_{j,k}}{\left(\Delta r\right)^2} \right. \nonumber \\
&\quad + \left( 1 +  \frac{\Delta\theta}{2}  \cot(\left[k+\flatfrac{1}{2}\right] \Delta \theta)   \right)       \sqrt{\frac{ \sin((k+\frac{1}{2}) \Delta \theta)}{\sin((k+\frac{3}{2}) \Delta \theta)}}      \frac{1}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \; g_{j, k+1} \nonumber \\
&\quad + \left( 1 -  \frac{\Delta\theta}{2}  \cot(\left[k+\flatfrac{1}{2}\right] \Delta \theta)   \right)       \sqrt{\frac{ \sin((k+\frac{1}{2}) \Delta \theta)}{\sin((k-\frac{1}{2}) \Delta \theta)}}      \frac{1}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \; g_{j, k-1} \nonumber \\
&\left. \quad - \frac{2}{\left[\left(j+\frac{1}{2}\right) \Delta r \, \Delta \theta\right]^2} \; g_{j, k} \right\rbrace + \cdots.
\end{align}
This result can be used to construct matrix operators in the $z$ and $\theta$ directions for the kinetic energy and the full Hamiltonian using identical methodology to the cylindrical-slice case.

\subsubsection{Probability Current}\label{sec:spherical_probability_current}

The probability current is defined as
\begin{align*}
\mathbf{J} = \frac{\hbar}{2m i} \left(\Psi^* \nabla \Psi -\Psi \nabla \Psi^* \right).
\end{align*}
Break this into components:
\begin{align*}
J^{(r)}  &= \frac{\hbar}{2m i} \left(\Psi^* \pdv{\Psi}{r} - \Psi \pdv{\Psi^*}{r} \right) \\
J^{(\theta)}  &= \frac{\hbar}{2m i} \left(\Psi^* \, \frac{1}{r}\pdv{\Psi}{\theta} - \Psi \,  \frac{1}{r}\pdv{\Psi^*}{\theta} \right).
\end{align*}
Apply the finite difference scheme to $J^{(r)}$:
\begin{align*}
J^{(r)} &= \frac{\hbar}{2m i} \left(\Psi^* \pdv{\Psi}{r} - \Psi \pdv{\Psi^*}{r} \right) \\
%
J^{(r)} &= \frac{\hbar}{2m i} \frac{1}{\sqrt{2 \pi r^2 \sin{\theta}}} \left(g^* \pdv{}{r}\left(\frac{g}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) - g \pdv{}{r}\left(\frac{g^*}{\sqrt{2 \pi r^2 \sin{\theta}}}\right) \right) \\
%
J^{(r)} &= \frac{\hbar}{2m i} \frac{1}{2 \pi r \sin{\theta}} \left(g^* \pdv{}{r}\left(\frac{g}{r}\right) - g \pdv{}{r}\left(\frac{g^*}{r}\right) \right) \\
%
J^{(r)}_{jk} &= \frac{\hbar}{2m i} \frac{1}{2 \pi \left(j+\frac{1}{2}\right) \Delta r \sin(\left(k + \frac{1}{2}\right) \Delta \theta)} \left(g^* \pdv{}{r}\left(\frac{g}{r}\right) - g \pdv{}{r}\left(\frac{g^*}{r}\right) \right) \\
\end{align*}

\subsection{Spherical Harmonic Mesh}\label{sec:spherical_harmonics}



%%%%%%%%%%%%%%%

\newpage
\section{Ideas}

Verlet integration for Bohmian Mechanics.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\newpage
\section{Chebyshev Polynomial Fitting}\label{app:chebyshev_fitting}



%%%%%%

\newpage
\section{Tridiagonal Matrix Algorithm}\label{app:tridiagonal_matrix_algorithm}
The time evolution algorithm (see Section \ref{sec:cylindrical_time_evolution}) depends on being able to perform four matrix operations. Two of the operations are simply multiplication of a vector by a very sparse matrix, and are easily and quickly accomplished by standard techniques for working with sparse matrices. The other two steps are complicated, since they involve multiplying by the inverse of a very sparse matrix - not an easy thing to find. Luckily, there is a fast algorithm to determine the \emph{result} of that multiplication (but not the matrix inverse itself).

Consider the problem of finding $\va{b}$ given
\begin{align*}
\vb{A}^{-1} \, \va{x} = \va{b} \\
\va{x} = \vb{A} \va{b},
\end{align*}
where $\va{x}$ and $\vb{A}$ are known but $\vb{A}^{-1}$ is not. The second line indicates that such a multiplication is equivalent to solving a linear system of equations.



%%%%%%

\newpage
\section{Householder Algorithm for Generating Tridiagonal Matrices}\label{app:householder}
The speed of the time evolution algorithm (see Section \ref{sec:cylindrical_time_evolution}) depends critically on the matrix operators being tridiagonal. Luckily, it is possible to turn any symmetric matrix into a tridiagonal matrix using the Householder algorithm.

%%%%%

\newpage
\section{Alternate Forms of the Radial Part of the Laplacian}\label{app:radial_laplacian}
The standard form of the radial part of the Laplacian applied to a function $f$ is
\begin{align}
\label{eqn:radial_laplacian__form0}
\laplacian_r{f}  = \frac{1}{r^2} \pdv{}{r} \left( r^2 \, \pdv{f}{r} \right).
\end{align}
This can be rewritten into two different forms. The first can be found by simply evaluating the outer derivative using the product rule:
\begin{align}
\label{eqn:radial_laplacian__form1}
\laplacian{}_r f &= \frac{1}{r^2} \pdv{}{r} \left( r^2 \, \pdv{f}{r} \right) \nonumber \\
\laplacian{}_r f &= \frac{1}{r^2} \left( 2r \, \pdv{f}{r} + r^2 \pdv[2]{f}{r} \right) \nonumber \\
\laplacian{}_r f &= \frac{2}{r} \, \pdv{f}{r} + \pdv[2]{f}{r}.
\end{align}
Alternatively, it turns out that this expression is also equivalent to \eqref{eqn:radial_laplacian__form0} (although it's not clear how you would figure this out except by guessing):
\begin{align*}
\frac{1}{r} \pdv[2]{}{r} \left( r \, f \right) &= \frac{1}{r} \pdv{}{r} \left(r \pdv{f}{r} + f\right) \\
&= \frac{1}{r} \left( \pdv{f}{r} + r \pdv[2]{f}{r} + \pdv{f}{r}  \right) \\
\frac{1}{r} \pdv[2]{}{r} \left( r \, f \right) &= \frac{2}{r} \pdv{f}{r} + r \pdv[2]{f}{r}.
\end{align*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\bibliographystyle{unsrt}
\bibliography{../library}

\end{document} 
